{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6c1f8b9-8047-430b-bf26-aec66b8d871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7ba872b5-9525-46d5-bb84-c872e81f106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\kgg07\\AppData\\Local\\Temp\\ipykernel_25752\\3270813984.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  df = pd.read_csv(\"C:\\AIdata\\DSA_features.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\AIdata\\DSA_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "05f122d2-88e5-4809-9e1c-06b97bc2ab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ad93024b-cef7-41c9-8a5b-31af64883984",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df[df['activity'] == 'lyingBack']\n",
    "abnormal_data = df[df['activity'] != 'lyingBack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "99dc5a15-198d-4cc5-a1a1-601d56d70272",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df.columns.difference(['activity', 'people'])\n",
    "normal_features = normal_data[feature_columns].values\n",
    "abnormal_features = abnormal_data[feature_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf627a80-7d2e-470e-9cde-ed9c346e6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(normal_features, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5865dfd1-5d67-4014-b29a-133ec25bc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = normal_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ae8af5e4-a040-4602-b7c9-6c6c84ef9007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgg07\\anaconda3\\envs\\learning3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoding_dim_symmetric = 128  # 대칭형 인코딩 차원\n",
    "symmetric_autoencoder = Sequential([\n",
    "    Dense(encoding_dim_symmetric, activation=\"relu\", input_shape=(input_dim,)),\n",
    "    Dense(input_dim, activation=\"sigmoid\")\n",
    "])\n",
    "symmetric_autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c95a5058-ffd1-40fa-b468-cf061c8104fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 5.6562 - val_loss: 4.9788\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1108 - val_loss: 4.8046\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7840 - val_loss: 4.7797\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0465 - val_loss: 4.7653\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7612 - val_loss: 4.7526\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8269 - val_loss: 4.7362\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0200 - val_loss: 4.7303\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7634 - val_loss: 4.7278\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7514 - val_loss: 4.7265\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8446 - val_loss: 4.7254\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.7394 - val_loss: 4.7243\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7931 - val_loss: 4.7230\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7660 - val_loss: 4.7219\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7247 - val_loss: 4.7209\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9208 - val_loss: 4.7197\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0602 - val_loss: 4.7192\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8645 - val_loss: 4.7188\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0820 - val_loss: 4.7185\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9309 - val_loss: 4.7182\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6980 - val_loss: 4.7180\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7877 - val_loss: 4.7178\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8114 - val_loss: 4.7177\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7203 - val_loss: 4.7174\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9389 - val_loss: 4.7172\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7144 - val_loss: 4.7173\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7772 - val_loss: 4.7170\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0475 - val_loss: 4.7168\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0202 - val_loss: 4.7166\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9242 - val_loss: 4.7164\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7557 - val_loss: 4.7163\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7436 - val_loss: 4.7162\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6955 - val_loss: 4.7161\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8070 - val_loss: 4.7161\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7759 - val_loss: 4.7158\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.9130 - val_loss: 4.7156\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7997 - val_loss: 4.7154\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.7073 - val_loss: 4.7152\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0687 - val_loss: 4.7151\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7335 - val_loss: 4.7150\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8579 - val_loss: 4.7150\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8144 - val_loss: 4.7149\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7429 - val_loss: 4.7148\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7030 - val_loss: 4.7149\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8184 - val_loss: 4.7148\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7534 - val_loss: 4.7147\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7102 - val_loss: 4.7146\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7406 - val_loss: 4.7147\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7354 - val_loss: 4.7146\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7681 - val_loss: 4.7146\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9969 - val_loss: 4.7146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x181bf486ae0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_autoencoder.fit(train_data, train_data, epochs=50, batch_size=32, validation_data=(val_data, val_data), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37efc955-2631-4e70-8a87-a1861c6fb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim_asymmetric = 64  # 비대칭형 인코딩 차원\n",
    "asymmetric_autoencoder = Sequential([\n",
    "    Dense(encoding_dim_asymmetric, activation=\"relu\", input_shape=(input_dim,)),\n",
    "    Dense(input_dim, activation=\"sigmoid\")\n",
    "])\n",
    "asymmetric_autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe1b401d-0211-4764-920f-db7992249829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 5.7502 - val_loss: 5.0903\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1638 - val_loss: 4.8603\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8217 - val_loss: 4.8039\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8817 - val_loss: 4.7810\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7927 - val_loss: 4.7626\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8273 - val_loss: 4.7502\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8605 - val_loss: 4.7438\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7595 - val_loss: 4.7381\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9096 - val_loss: 4.7317\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7602 - val_loss: 4.7296\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7597 - val_loss: 4.7282\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8878 - val_loss: 4.7271\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9387 - val_loss: 4.7262\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7665 - val_loss: 4.7253\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0434 - val_loss: 4.7248\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0797 - val_loss: 4.7243\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8010 - val_loss: 4.7238\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8551 - val_loss: 4.7234\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7358 - val_loss: 4.7232\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6982 - val_loss: 4.7229\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8012 - val_loss: 4.7226\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8046 - val_loss: 4.7224\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7737 - val_loss: 4.7221\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9156 - val_loss: 4.7220\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7019 - val_loss: 4.7217\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6944 - val_loss: 4.7216\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.7715 - val_loss: 4.7215\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8118 - val_loss: 4.7214\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8141 - val_loss: 4.7212\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8141 - val_loss: 4.7210\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7609 - val_loss: 4.7208\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8720 - val_loss: 4.7208\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9558 - val_loss: 4.7207\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7463 - val_loss: 4.7206\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9862 - val_loss: 4.7205\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7192 - val_loss: 4.7204\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6858 - val_loss: 4.7203\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8982 - val_loss: 4.7202\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8439 - val_loss: 4.7201\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7136 - val_loss: 4.7201\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8163 - val_loss: 4.7199\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8365 - val_loss: 4.7199\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8146 - val_loss: 4.7198\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7391 - val_loss: 4.7198\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7909 - val_loss: 4.7197\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7250 - val_loss: 4.7195\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8484 - val_loss: 4.7194\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8628 - val_loss: 4.7192\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8105 - val_loss: 4.7192\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7329 - val_loss: 4.7190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x181beecf9b0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asymmetric_autoencoder.fit(train_data, train_data, epochs=50, batch_size=32, validation_data=(val_data, val_data), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db7e27e8-9888-4401-89ee-704ca9c90b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "symmetric_normal_recon = symmetric_autoencoder.predict(normal_features)\n",
    "symmetric_abnormal_recon = symmetric_autoencoder.predict(abnormal_features)\n",
    "symmetric_normal_mse = mean_squared_error(normal_features, symmetric_normal_recon)\n",
    "symmetric_abnormal_mse = mean_squared_error(abnormal_features, symmetric_abnormal_recon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e5a1fb9-94b4-4293-a716-de007d05fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "asymmetric_normal_recon = asymmetric_autoencoder.predict(normal_features)\n",
    "asymmetric_abnormal_recon = asymmetric_autoencoder.predict(abnormal_features)\n",
    "asymmetric_normal_mse = mean_squared_error(normal_features, asymmetric_normal_recon)\n",
    "asymmetric_abnormal_mse = mean_squared_error(abnormal_features, asymmetric_abnormal_recon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8977d0d8-7397-44dd-ad74-560dd69b0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"Symmetric Autoencoder\", \"Asymmetric Autoencoder\"],\n",
    "    \"Normal Data MSE\": [symmetric_normal_mse, asymmetric_normal_mse],\n",
    "    \"Abnormal Data MSE\": [symmetric_abnormal_mse, asymmetric_abnormal_mse]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd8f4c1c-0d4a-4623-a989-58a0e0e18000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Normal Data MSE  Abnormal Data MSE\n",
      "0   Symmetric Autoencoder          4.79119          83.210945\n",
      "1  Asymmetric Autoencoder          4.79539          83.393440\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7a64a5a9-473c-46cc-a248-34a2b82ce942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0082a83-821f-4329-89c1-97ff0302c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Symmetric Autoencoder\", \"Asymmetric Autoencoder\"]\n",
    "normal_mse = [4.787694, 4.794042]\n",
    "abnormal_mse = [83.006653, 83.284831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc462b8b-8c57-48fc-bd42-8f29d0f7a0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(models, normal_mse, color='blue', alpha=0.6, label='Normal Data MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8419d0d-9b8e-423f-bcdb-b281258e6d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
